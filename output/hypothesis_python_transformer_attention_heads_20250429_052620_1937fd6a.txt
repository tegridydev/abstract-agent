Topic: python transformer attention heads

Literature Citations:
Relevant papers from multiple sources:
- [arXiv] GMAR: Gradient-Driven Multi-Head Attention Rollout for Vision Transformer Interpretability (2025)
  http://arxiv.org/abs/2504.19414v1
  Authors: Sehyeong Jo, Gangjae Jang, Haesol Park
  Summary: The Vision Transformer (ViT) has made significant advancements in computer
vision, utilizing self-attention mechanisms to achieve state-of-the-art
performance across various tasks, including image classification, object
detection, and segmentation. Its architectural flexibility and capabilities
have...
- [arXiv] MoH: Multi-Head Attention as Mixture-of-Head Attention (2024)
  http://arxiv.org/abs/2410.11842v1
  Authors: Peng Jin, Bo Zhu, Li Yuan, Shuicheng Yan
  Summary: In this work, we upgrade the multi-head attention mechanism, the core of the
Transformer model, to improve efficiency while maintaining or surpassing the
previous accuracy level. We show that multi-head attention can be expressed in
the summation form. Drawing on the insight that not all attention h...
- [Semantic Scholar] RecurFormer: Not All Transformer Heads Need Self-Attention (2024)
  https://www.semanticscholar.org/paper/642dbe8e74c94a61488414e3182b6e31e36f7f37
  Authors: Ruiqing Yan, Linghan Zheng, Xingbo Du, Han Zou, Yufeng Guo, Jianfei Yang
  Summary: Transformer-based large language models (LLMs) excel in modeling complex language patterns but face significant computational costs during inference, especially with long inputs due to the attention mechanism's memory overhead. We observe that certain attention heads exhibit a distribution where the...
- [arXiv] Attention-Only Transformers and Implementing MLPs with Attention Heads (2023)
  http://arxiv.org/abs/2309.08593v1
  Authors: Robert Huben, Valerie Morris
  Summary: The transformer architecture is widely used in machine learning models and
consists of two alternating sublayers: attention heads and MLPs. We prove that
an MLP neuron can be implemented by a masked attention head with internal
dimension 1 so long as the MLP's activation function comes from a restri...
- [Semantic Scholar] Improving Transformer-Based End-to-End Speaker Diarization by Assigning Auxiliary Losses to Attention Heads (2023)
  https://www.semanticscholar.org/paper/d90e7f51c905dfbc201f1cfe978d83b51d16b2aa
  Authors: Ye-Rin Jeoung, Joon-Young Yang, Jeonghwan Choi, Joon‐Hyuk Chang
  Summary: Transformer-based end-to-end neural speaker diarization (EEND) models utilize the multi-head self-attention (SA) mechanism to enable accurate speaker label prediction in overlapped speech regions. In this study, to enhance the training effectiveness of SA-EEND models, we propose the use of auxiliary...
- [Semantic Scholar] Bias A-head? Analyzing Bias in Transformer-Based Language Model Attention Heads (2023)
  https://www.semanticscholar.org/paper/361d64b13896d8859b0eb138546ddd846da36b1b
  Authors: Yi Yang, Hanyu Duan, Ahmed Abbasi, John P. Lalor, K. Tam
  Summary: Transformer-based pretrained large language models (PLM) such as BERT and GPT have achieved remarkable success in NLP tasks. However, PLMs are prone to encoding stereotypical biases. Although a burgeoning literature has emerged on stereotypical bias mitigation in PLMs, such as work on debiasing gend...
- [Crossref] Plausibility Processing in Transformer Language Models: Focusing on the Role of Attention Heads in GPT (2023)
  https://doi.org/10.18653/v1/2023.findings-emnlp.27
  Authors: Soo Ryu
  Summary: ...


Literature Summary:
[Summarization failed: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download]

Agent A:
[ERROR] Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download

Agent B:
[ERROR] 'breakdown'

Agent C:
[ERROR] 'breakdown'

Agent D:
[ERROR] 'synthesis'

Agent E:
[ERROR] 'novel_hypothesis'

Novelty Assessment:
[Novelty detection failed: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download]

References:
- [arXiv] GMAR: Gradient-Driven Multi-Head Attention Rollout for Vision Transformer Interpretability (2025)
  http://arxiv.org/abs/2504.19414v1
  Authors: Sehyeong Jo, Gangjae Jang, Haesol Park

- [arXiv] MoH: Multi-Head Attention as Mixture-of-Head Attention (2024)
  http://arxiv.org/abs/2410.11842v1
  Authors: Peng Jin, Bo Zhu, Li Yuan, Shuicheng Yan

- [Semantic Scholar] RecurFormer: Not All Transformer Heads Need Self-Attention (2024)
  https://www.semanticscholar.org/paper/642dbe8e74c94a61488414e3182b6e31e36f7f37
  Authors: Ruiqing Yan, Linghan Zheng, Xingbo Du, Han Zou, Yufeng Guo, Jianfei Yang

- [arXiv] Attention-Only Transformers and Implementing MLPs with Attention Heads (2023)
  http://arxiv.org/abs/2309.08593v1
  Authors: Robert Huben, Valerie Morris

- [Semantic Scholar] Improving Transformer-Based End-to-End Speaker Diarization by Assigning Auxiliary Losses to Attention Heads (2023)
  https://www.semanticscholar.org/paper/d90e7f51c905dfbc201f1cfe978d83b51d16b2aa
  Authors: Ye-Rin Jeoung, Joon-Young Yang, Jeonghwan Choi, Joon‐Hyuk Chang

- [Semantic Scholar] Bias A-head? Analyzing Bias in Transformer-Based Language Model Attention Heads (2023)
  https://www.semanticscholar.org/paper/361d64b13896d8859b0eb138546ddd846da36b1b
  Authors: Yi Yang, Hanyu Duan, Ahmed Abbasi, John P. Lalor, K. Tam

- [Crossref] Plausibility Processing in Transformer Language Models: Focusing on the Role of Attention Heads in GPT (2023)
  https://doi.org/10.18653/v1/2023.findings-emnlp.27
  Authors: Soo Ryu

Final Hypothesis (Agent E):
[ERROR] 'novel_hypothesis'
